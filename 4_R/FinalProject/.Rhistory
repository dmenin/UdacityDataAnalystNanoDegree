library(twitteR)
library(igraph)
library(stringr)
tweets = userTimeline("dmenin", n=1000)
tweets[1]
tweets[1]$getText)()
tweets[1]$getText()
tweet_txt = sapply(tweets, function(x) x$getText())
tweet_txt[1]
l <- list(a = 1:10, b = 11:20)
l
l.mean <- sapply(l, mean)
sapply(l, mean)
lapply(l, mean)
l <- lapply(l, mean)
class(l)
s<- sapply(l, mean)
class(s)
tweets[1]
tweets[1][1]
tweets[1][1]$getText()
tweet_txt = sapply(tweets, function(x) x$getText())
tweet_txt
grep("(RT|via)((?:\b\W*@\w+)+)", tweets, ignore.case=TRUE, value=TRUE)
grep("(RT|via)((?:\b\W*@\w+)+)", tweets,
ignore.case=TRUE, value=TRUE)
grep("(RT|via)((?:\b\W*@\w+)+)", tweets_txt, ignore.case=TRUE, value=TRUE)
grep("(RT|via)((?:\b\W*@\w+)+)", tweets[1], ignore.case=TRUE, value=TRUE)
grep("(RT|via)((?:\b\W*@\w+)+)", tweets[1][1], ignore.case=TRUE, value=TRUE)
grep("(RT|via)((?:\b*@\w+)+)", tweets, ignore.case=TRUE, value=TRUE)
grep("(RT|via)((?:\b*@+)+)", tweets, ignore.case=TRUE, value=TRUE)
tweets = userTimeline("mashable", n=1000)
tweet_txt = sapply(tweets, function(x) x$getText())
grep("(RT|via)((?:\b\W*@\w+)+)", tweets, ignore.case=TRUE, value=TRUE)
rt_patterns = grep("(RT|via)((?:\b\W*@\w+)+)",
tweet_txt, ignore.case=TRUE)
rt_patterns = grep("(RT|via)((?:\b\W*@\w+)+)", tweet_txt, ignore.case=TRUE)
tweet_txt[1]
rt_patterns = grep("(RT|via)((?:\b\W*@\w+)+)", tweet_txt[1], ignore.case=TRUE)
grep("(RT|via)((?:\b\\W*@\\w+)+)", tweets, ignore.case=TRUE, value=TRUE)
rt_patterns = grep("(RT|via)((?:\b\\W*@\w+)+)", tweet_txt, ignore.case=TRUE)
rt_patterns = grep("(RT|via)((?:\b\\W*@\\w+)+)", tweet_txt, ignore.case=TRUE)
grep("(RT|via)((?:\b\\W*@\\w+)+)", tweet_txt, ignore.case=TRUE)
tweet_txt
write.csv(tweet_txt, "tweet.csv")
grep("(RT|via)", tweet_txt, ignore.case=TRUE)
rt_patterns = grep("(RT|via)", tweet_txt, ignore.case=TRUE)
tweet_txt[rt_patterns]
grep("(RT|via)((?:\b\\W*@\\w+)+)", tweet_txt, ignore.case=TRUE)
grep("(RT|via)((?:\b\\W*@+)+)", tweet_txt, ignore.case=TRUE)
grep("(RT|via)((?:\b*@+)+)", tweet_txt, ignore.case=TRUE)
grep("(RT|via)((?:*@+)+)", tweet_txt, ignore.case=TRUE)
rt_patterns = grep("(RT|via)((?:\b\W*@\w+)+)",tweet_txt, ignore.case=TRUE)
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",tweet_txt, ignore.case=TRUE)
rt_patterns
grep("(RT|via)((?:\\b\\W*@\\w+)+)",tweet_txt, ignore.case=TRUE)
tweet_txt[rt_patterns]
as.list(1:length(rt_patterns))
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = tweets[[rt_patterns[i]]]
# get retweet source
poster = str_extract_all(twit$getText(),"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$getScreenName(), length(poster))
}
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
#two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
rt_graph = graph.edgelist(retweeter_poster)
# get vertex names
ver_labs = get.vertex.attribute(rt_graph, "name", index=V(rt_graph))
# choose some layout
glay = layout.fruchterman.reingold(rt_graph)
# plot
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color="gray25",
vertex.size=10,
vertex.label=ver_labs,
vertex.label.family="sans",
vertex.shape="none",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.95, s=1, v=.7, alpha=0.5))
# add title
title("nTweets from the User account @mashable: Who retweets whom",
cex.main=1, col.main="gray95")
tweets = userTimeline("dmenin", n=1000)
tweet_txt = sapply(tweets, function(x) x$getText())
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",tweet_txt, ignore.case=TRUE)
tweet_txt[rt_patterns]
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = tweets[[rt_patterns[i]]]
# get retweet source
poster = str_extract_all(twit$getText(),"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$getScreenName(), length(poster))
}
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
#two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
rt_graph = graph.edgelist(retweeter_poster)
# get vertex names
ver_labs = get.vertex.attribute(rt_graph, "name", index=V(rt_graph))
# choose some layout
glay = layout.fruchterman.reingold(rt_graph)
# plot
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color="gray25",
vertex.size=10,
vertex.label=ver_labs,
vertex.label.family="sans",
vertex.shape="none",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.95, s=1, v=.7, alpha=0.5))
# add title
title("nTweets from the User account @mashable: Who retweets whom",
cex.main=1, col.main="gray95")
tweets = userTimeline("dmenin", n=10)
tweet_txt = sapply(tweets, function(x) x$getText())
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",tweet_txt, ignore.case=TRUE)
tweet_txt[rt_patterns]
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = tweets[[rt_patterns[i]]]
# get retweet source
poster = str_extract_all(twit$getText(),"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$getScreenName(), length(poster))
}
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
#two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
rt_graph = graph.edgelist(retweeter_poster)
# get vertex names
ver_labs = get.vertex.attribute(rt_graph, "name", index=V(rt_graph))
# choose some layout
glay = layout.fruchterman.reingold(rt_graph)
# plot
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color="gray25",
vertex.size=10,
vertex.label=ver_labs,
vertex.label.family="sans",
vertex.shape="none",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.95, s=1, v=.7, alpha=0.5))
# add title
title("nTweets from the User account @mashable: Who retweets whom",
cex.main=1, col.main="gray95")
tweet_txt
userTimeline("dmenin", n=2)
tweets = userTimeline("dmenin", n=10)
tweet_txt = sapply(tweets, function(x) x$getText())
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",tweet_txt, ignore.case=TRUE)
tweet_txt[rt_patterns]
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = tweets[[rt_patterns[i]]]
# get retweet source
poster = str_extract_all(twit$getText(),"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$getScreenName(), length(poster))
}
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
#two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
rt_graph = graph.edgelist(retweeter_poster)
# get vertex names
ver_labs = get.vertex.attribute(rt_graph, "name", index=V(rt_graph))
# choose some layout
glay = layout.fruchterman.reingold(rt_graph)
# plot
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color="gray25",
vertex.size=10,
vertex.label=ver_labs,
vertex.label.family="sans",
vertex.shape="none",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.95, s=1, v=.7, alpha=0.5))
# add title
title("nTweets from the User account @mashable: Who retweets whom",
cex.main=1, col.main="gray95")
tweets = userTimeline("mashable", n=1000)
tweet_txt = sapply(tweets, function(x) x$getText())
rt_patterns = grep("(RT|via)((?:\\b\\W*@\\w+)+)",tweet_txt, ignore.case=TRUE)
tweet_txt[rt_patterns]
who_retweet = as.list(1:length(rt_patterns))
who_post = as.list(1:length(rt_patterns))
for (i in 1:length(rt_patterns))
{
# get tweet with retweet entity
twit = tweets[[rt_patterns[i]]]
# get retweet source
poster = str_extract_all(twit$getText(),"(RT|via)((?:\\b\\W*@\\w+)+)")
#remove ':'
poster = gsub(":", "", unlist(poster))
# name of retweeted user
who_post[[i]] = gsub("(RT @|via @)", "", poster, ignore.case=TRUE)
# name of retweeting user
who_retweet[[i]] = rep(twit$getScreenName(), length(poster))
}
who_post = unlist(who_post)
who_retweet = unlist(who_retweet)
#two column matrix of edges
retweeter_poster = cbind(who_retweet, who_post)
# generate graph
rt_graph = graph.edgelist(retweeter_poster)
# get vertex names
ver_labs = get.vertex.attribute(rt_graph, "name", index=V(rt_graph))
# choose some layout
glay = layout.fruchterman.reingold(rt_graph)
# plot
par(bg="gray15", mar=c(1,1,1,1))
plot(rt_graph, layout=glay,
vertex.color="gray25",
vertex.size=10,
vertex.label=ver_labs,
vertex.label.family="sans",
vertex.shape="none",
vertex.label.color=hsv(h=0, s=0, v=.95, alpha=0.5),
vertex.label.cex=0.85,
edge.arrow.size=0.8,
edge.arrow.width=0.5,
edge.width=3,
edge.color=hsv(h=.95, s=1, v=.7, alpha=0.5))
# add title
title("nTweets from the User account @mashable: Who retweets whom",
cex.main=1, col.main="gray95")
tweets = searchTwitter("Social Media", n=20, cainfo="cacert.pem")
api_key <- "zjtQwiqHGXg8qaCXTIa4x7OFx"
api_secret <- "phHgOkCVM1a5fXUP36qpcCv9Rot4FxzHqF5qABvjq3r1FWcpft"
access_token <- "45141109-rIXQxFLqM3FAtV4XKzlswxOzKbBL9zhwjkSDmpTh0"
access_token_secret <- "JExDufSFXeURJUalHTtDt1Z2RNgAsXDqwStlkLnwfnQ4k"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
tweets = searchTwitter("Social Media", n=20, cainfo="cacert.pem")
search_twitter_and_store("Social Media", n=20, cainfo="cacert.pem")
searchTwitter()
?searchTwitter
tweets = searchTwitter("Social Media", n=20, cainfo="cacert.pem")
tweets = searchTwitter("Social Media", n=20)
tweets
setStatusSource
getStatusSource
devices <- sapply(tweets, function(x) x$getStatusSource())
devices <- gsub("","", devices)
devices <- strsplit(devices, ">")
devices <- sapply(devices,function(x) ifelse(length(x) > 1, x[2], x[1]))[/code]
devices <- sapply(devices,function(x) ifelse(length(x) > 1, x[2], x[1]))
pie(table(sources))
pie(table(devices))
pie(table(devices))
devices
devices
tweets[1]
tweets[1]$text
tweets[1][1]$text
tweets[1][1]$txt
tweets[1]$txt
text <- sapply(tweets, function(x) x$getText())
text
sapply(tweets, function(x) x$getStatusSource())
devices <- sapply(tweets, function(x) x$getStatusSource())
gsub("","", devices)
?gsub
devices <- gsub("","", devices)
strsplit(devices, ">")
tweets = searchTwitter("Social Media", n=1)
devices <- sapply(tweets, function(x) x$getStatusSource())
devices
devices <- gsub("","", devices)
devices
devices <- strsplit(devices, ">")
devices
sapply(devices,function(x) ifelse(length(x) > 1, x[2], x[1]))
source(“http://biostat.jhsph.edu/~jleek/code/twitterMap.R”)
source('http://biostat.jhsph.edu/~jleek/code/twitterMap.R')
twitterMap("dmenin", fileName="foo.pdf", nMax=500)
getwd()
rm(list = ls())
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con, 10)
close(con)
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
itteR)
rm(list = ls())
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con, 1)
close(con)
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus
rm(list = ls())
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con, 2)
close(con)
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus
----
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
myCorpus
myCorpus[1]
class(myCorpus)
myCorpus
myCorpus[[1]]
myCorpus[[2]]
myCorpus[1][2]
rm(list = ls())
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con, 10)
close(con)
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
myCorpus <- tm_map(myCorpus, removePunctuation) # remove punctuation
myCorpus <- tm_map(myCorpus, removeNumbers) #remove numbers
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x) # remove URLs
myCorpus <- tm_map(myCorpus, removeURL)
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
myCorpus <- tm_map(myCorpus, removePunctuation) # remove punctuation
myCorpus <- tm_map(myCorpus, removeNumbers) #remove numbers
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x) # remove URLs
myCorpus <- tm_map(myCorpus, removeURL)
myCorpus <- tm_map(myCorpus, PlainTextDocument) #http://stackoverflow.com/questions/24191728/documenttermmatrix-error-on-corpus-argument
tdm <- TermDocumentMatrix(myCorpus, control = list(wordLengths = c(1, Inf)))
freq.terms <- findFreqTerms(tdm, lowfreq = 10)
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 10)
df <- data.frame(term = names(term.freq), freq = term.freq) #WORD COUNT
df
freq.terms <- findFreqTerms(tdm, lowfreq = 1)
freq.terms
term.freq <- rowSums(as.matrix(tdm))
freq.terms
term.freq <- subset(term.freq, term.freq >= 1)
term.freq
rowSums(as.matrix(tdm))
myCorpus <- tm_map(myCorpus, PlainTextDocument) #http://stackoverflow.com/questions/24191728/documenttermmatrix-error-on-corpus-argument
tdm <- TermDocumentMatrix(myCorpus, control = list(wordLengths = c(1, Inf)))
rowSums(as.matrix(tdm))
rm(list = ls())
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con, 1)
close(con)
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
myCorpus <- tm_map(myCorpus, removePunctuation) # remove punctuation
myCorpus <- tm_map(myCorpus, removeNumbers) #remove numbers
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x) # remove URLs
myCorpus <- tm_map(myCorpus, removeURL)
myCorpus <- tm_map(myCorpus, PlainTextDocument) #http://stackoverflow.com/questions/24191728/documenttermmatrix-error-on-corpus-argument
tdm <- TermDocumentMatrix(myCorpus, control = list(wordLengths = c(1, Inf)))
rowSums(as.matrix(tdm))
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con, 3)
close(con)
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
myCorpus <- tm_map(myCorpus, removePunctuation) # remove punctuation
myCorpus <- tm_map(myCorpus, removeNumbers) #remove numbers
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x) # remove URLs
myCorpus <- tm_map(myCorpus, removeURL)
myCorpus <- tm_map(myCorpus, PlainTextDocument) #http://stackoverflow.com/questions/24191728/documenttermmatrix-error-on-corpus-argument
tdm <- TermDocumentMatrix(myCorpus, control = list(wordLengths = c(1, Inf)))
rowSums(as.matrix(tdm))
term.freq <- rowSums(as.matrix(tdm))
term.freq
class(term.freq)
subset(term.freq, term.freq >= 1)
subset(term.freq, term.freq > 1)
df <- data.frame(term = names(term.freq), freq = term.freq) #WORD COUNT
df
names(term.freq)
term.freq
term.freq <- subset(term.freq, term.freq > 1)
term.freq
df <- data.frame(term = names(term.freq), freq = term.freq) #WORD COUNT
df
rm(list = ls())
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con, 3)
close(con)
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
myCorpus <- tm_map(myCorpus, removePunctuation) # remove punctuation
myCorpus <- tm_map(myCorpus, removeNumbers) #remove numbers
removeURL <- function(x) gsub("http[[:alnum:]]*", "", x) # remove URLs
myCorpus <- tm_map(myCorpus, removeURL)
myCorpus <- tm_map(myCorpus, PlainTextDocument) #http://stackoverflow.com/questions/24191728/documenttermmatrix-error-on-corpus-argument
tdm <- TermDocumentMatrix(myCorpus, control = list(wordLengths = c(1, Inf)))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 1)
df <- data.frame(term = names(term.freq), freq = term.freq) #WORD COUNT
df
rm(list = ls())
con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
a<- readLines(con)
close(con)
rm(list = ls())
#con <- file("c:\\git\\capstone\\final\\en_US_small\\en_US.twitter_small.txt", "r")
con <- file("c:\\git\\capstone\\final\\en_US\\en_US.twitter.txt", "r")
a<- readLines(con)
close(con)
df<-as.data.frame(a)
names(df) <- c("text")
myCorpus <- Corpus(VectorSource(df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
rm(list = ls())
shiny::runApp('C:/git/capstone/TextPredictionApp')
shiny::runApp('C:/git/capstone/TextPredictionApp')
shiny::runApp('C:/git/capstone/TextPredictionApp')
shiny::runApp('C:/git/capstone/TextPredictionApp')
shiny::runApp('C:/git/capstone/TextPredictionApp')
shiny::runApp('C:/git/capstone/TextPredictionApp')
df$rating <- ordered(df$rating,levels =
c('Bad', 'Average', 'Good', 'Excellent'))
install.packages("lars")
library(lars)
data(diabetes)
attach(diabetes)
diabetes
View(diabetes)
?data
?attach
?diabetes
View(diabetes)
cv.lars(x2,y,trace=TRUE,max.steps=80)
setwd("C:/git/UdacityDataAnalystNanoDegree/4_R/FinalProject/")
df<-read.csv("wineQualityWhites.csv")
x2
install.packages("glmnet")
library(glmnet)
df
?model.matrix
df$quality <- as.factor(df$quality)
model.matrix(quality ~ .)
model.matrix(data=df, quality ~ .)
model.matrix(data=df, quality ~ .)[,-1]
xfactors <- model.matrix(data=df, quality ~ .)[,-1]
xfactors
